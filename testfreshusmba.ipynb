{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPMt9MpBm0pOOIlOyBg/Vlq",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ghitabnr/Orange-detector-model/blob/main/testfreshusmba.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CDGRYpLkAWoo",
        "outputId": "1298f81e-ee9f-49d9-fdee-e4d5fcede14d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from pathlib import Path\n",
        "import torch\n",
        "import os\n",
        "!git clone https://github.com/ultralytics/yolov5\n",
        "%cd yolov5\n",
        "%pip install -r requirements.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mgp5u6GmAebx",
        "outputId": "6d7a67a3-5349-4805-e264-4cf0793dcea8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'yolov5' already exists and is not an empty directory.\n",
            "/content/yolov5\n",
            "Requirement already satisfied: gitpython>=3.1.30 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 5)) (3.1.43)\n",
            "Requirement already satisfied: matplotlib>=3.3 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 6)) (3.7.1)\n",
            "Requirement already satisfied: numpy>=1.23.5 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 7)) (1.25.2)\n",
            "Requirement already satisfied: opencv-python>=4.1.1 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 8)) (4.8.0.76)\n",
            "Requirement already satisfied: pillow>=10.3.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 9)) (10.3.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 10)) (5.9.5)\n",
            "Requirement already satisfied: PyYAML>=5.3.1 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 11)) (6.0.1)\n",
            "Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 12)) (2.31.0)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 13)) (1.11.4)\n",
            "Requirement already satisfied: thop>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 14)) (0.1.1.post2209072238)\n",
            "Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 15)) (2.2.1+cu121)\n",
            "Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 16)) (0.17.1+cu121)\n",
            "Requirement already satisfied: tqdm>=4.64.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 17)) (4.66.2)\n",
            "Requirement already satisfied: ultralytics>=8.0.232 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 18)) (8.2.2)\n",
            "Requirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 27)) (2.0.3)\n",
            "Requirement already satisfied: seaborn>=0.11.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 28)) (0.13.1)\n",
            "Requirement already satisfied: setuptools>=65.5.1 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 42)) (67.7.2)\n",
            "Requirement already satisfied: wheel>=0.38.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 50)) (0.43.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from gitpython>=3.1.30->-r requirements.txt (line 5)) (4.0.11)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3->-r requirements.txt (line 6)) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3->-r requirements.txt (line 6)) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3->-r requirements.txt (line 6)) (4.51.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3->-r requirements.txt (line 6)) (1.4.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3->-r requirements.txt (line 6)) (24.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3->-r requirements.txt (line 6)) (3.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3->-r requirements.txt (line 6)) (2.8.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->-r requirements.txt (line 12)) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->-r requirements.txt (line 12)) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->-r requirements.txt (line 12)) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->-r requirements.txt (line 12)) (2024.2.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->-r requirements.txt (line 15)) (3.13.4)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->-r requirements.txt (line 15)) (4.11.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->-r requirements.txt (line 15)) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->-r requirements.txt (line 15)) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->-r requirements.txt (line 15)) (3.1.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->-r requirements.txt (line 15)) (2023.6.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->-r requirements.txt (line 15)) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->-r requirements.txt (line 15)) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->-r requirements.txt (line 15)) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->-r requirements.txt (line 15)) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->-r requirements.txt (line 15)) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->-r requirements.txt (line 15)) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->-r requirements.txt (line 15)) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->-r requirements.txt (line 15)) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->-r requirements.txt (line 15)) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->-r requirements.txt (line 15)) (2.19.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->-r requirements.txt (line 15)) (12.1.105)\n",
            "Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->-r requirements.txt (line 15)) (2.2.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.8.0->-r requirements.txt (line 15)) (12.4.127)\n",
            "Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.10/dist-packages (from ultralytics>=8.0.232->-r requirements.txt (line 18)) (9.0.0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.4->-r requirements.txt (line 27)) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.4->-r requirements.txt (line 27)) (2024.1)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from gitdb<5,>=4.0.1->gitpython>=3.1.30->-r requirements.txt (line 5)) (5.0.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3->-r requirements.txt (line 6)) (1.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.8.0->-r requirements.txt (line 15)) (2.1.5)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.8.0->-r requirements.txt (line 15)) (1.3.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_path = '/content/drive/MyDrive/ColabNotebooks/best1.pt'\n",
        "model = torch.load(model_path, map_location=torch.device('cpu'))"
      ],
      "metadata": {
        "id": "-x1tYCupAgiE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python /content/yolov5/detect.py --weights /content/drive/MyDrive/ColabNotebooks/best1.pt --img 1280 --conf 0.1 --source /content/drive/MyDrive/ColabNotebooks/data_combined/dataset1/OrangeDetection.v1i.yolov5pytorch/valid/images"
      ],
      "metadata": {
        "id": "GJJXw8NcAk2Y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "52734236-597c-42d7-c35a-d369d31ada8b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/content/drive/MyDrive/ColabNotebooks/best1.pt'], source=/content/drive/MyDrive/ColabNotebooks/data_combined/dataset1/OrangeDetection.v1i.yolov5pytorch/valid/images, data=data/coco128.yaml, imgsz=[1280, 1280], conf_thres=0.1, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_csv=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
            "YOLOv5 🚀 v7.0-304-g22361691 Python-3.10.12 torch-2.2.1+cu121 CPU\n",
            "\n",
            "Fusing layers... \n",
            "Model summary: 157 layers, 1760518 parameters, 0 gradients, 4.1 GFLOPs\n",
            "image 1/90 /content/drive/MyDrive/ColabNotebooks/data_combined/dataset1/OrangeDetection.v1i.yolov5pytorch/valid/images/00020ebf74c4881c_jpg.rf.9f634b40cb032593772c8c9f115467f8.jpg: 1280x1280 3 oranges, 711.2ms\n",
            "image 2/90 /content/drive/MyDrive/ColabNotebooks/data_combined/dataset1/OrangeDetection.v1i.yolov5pytorch/valid/images/003d3be546fe8fc2_jpg.rf.85e7563a1cf4b59b8bd9c31318db16c1.jpg: 1280x1280 18 oranges, 649.4ms\n",
            "image 3/90 /content/drive/MyDrive/ColabNotebooks/data_combined/dataset1/OrangeDetection.v1i.yolov5pytorch/valid/images/0183c8d78acd17a8_jpg.rf.f7ce64997417c3409240c739d2998ac4.jpg: 1280x1280 18 oranges, 633.3ms\n",
            "image 4/90 /content/drive/MyDrive/ColabNotebooks/data_combined/dataset1/OrangeDetection.v1i.yolov5pytorch/valid/images/0187c2617fd79971_jpg.rf.dc3d89e2cb34cfe162534a5fb269558a.jpg: 1280x1280 14 oranges, 677.7ms\n",
            "image 5/90 /content/drive/MyDrive/ColabNotebooks/data_combined/dataset1/OrangeDetection.v1i.yolov5pytorch/valid/images/046d9a7a741d1401_jpg.rf.0b4e607410cd223d9120b3711b35ff5a.jpg: 1280x1280 3 oranges, 983.6ms\n",
            "image 6/90 /content/drive/MyDrive/ColabNotebooks/data_combined/dataset1/OrangeDetection.v1i.yolov5pytorch/valid/images/05331fc123810131_jpg.rf.a795bd1e6a646a4ce1c55ffd917813b9.jpg: 1280x1280 18 oranges, 1006.2ms\n",
            "image 7/90 /content/drive/MyDrive/ColabNotebooks/data_combined/dataset1/OrangeDetection.v1i.yolov5pytorch/valid/images/0612ee8f4a9aa481_jpg.rf.dd5f29bddc985b2356ce2301610d83e6.jpg: 1280x1280 25 oranges, 630.5ms\n",
            "image 8/90 /content/drive/MyDrive/ColabNotebooks/data_combined/dataset1/OrangeDetection.v1i.yolov5pytorch/valid/images/07624bb579a2ed83_jpg.rf.43c8f579c866e1fedb7e171a5b1a3efb.jpg: 1280x1280 3 oranges, 673.0ms\n",
            "image 9/90 /content/drive/MyDrive/ColabNotebooks/data_combined/dataset1/OrangeDetection.v1i.yolov5pytorch/valid/images/098df11906519df1_jpg.rf.305d0e4c9ce6af8eb763125010dea859.jpg: 1280x1280 35 oranges, 645.4ms\n",
            "image 10/90 /content/drive/MyDrive/ColabNotebooks/data_combined/dataset1/OrangeDetection.v1i.yolov5pytorch/valid/images/09abdc6806818437_jpg.rf.55aa3029524e0524809a25fba7701489.jpg: 1280x1280 13 oranges, 699.7ms\n",
            "image 11/90 /content/drive/MyDrive/ColabNotebooks/data_combined/dataset1/OrangeDetection.v1i.yolov5pytorch/valid/images/0a81efe1a6a8adc3_jpg.rf.d683f26ef13c92208c710248c46a8b50.jpg: 1280x1280 160 oranges, 610.4ms\n",
            "image 12/90 /content/drive/MyDrive/ColabNotebooks/data_combined/dataset1/OrangeDetection.v1i.yolov5pytorch/valid/images/100c559a2dcdda69_jpg.rf.dc7512370d93fa58da3f8e2c9741d5db.jpg: 1280x1280 3 oranges, 632.1ms\n",
            "image 13/90 /content/drive/MyDrive/ColabNotebooks/data_combined/dataset1/OrangeDetection.v1i.yolov5pytorch/valid/images/10ed49e38561d2ee_jpg.rf.44aadf870fda2cc84a0051040cd8870f.jpg: 1280x1280 210 oranges, 615.5ms\n",
            "image 14/90 /content/drive/MyDrive/ColabNotebooks/data_combined/dataset1/OrangeDetection.v1i.yolov5pytorch/valid/images/11bbe2b0de0dd100_jpg.rf.e3b899621ee29532dcdcea7751b18873.jpg: 1280x1280 9 oranges, 706.5ms\n",
            "image 15/90 /content/drive/MyDrive/ColabNotebooks/data_combined/dataset1/OrangeDetection.v1i.yolov5pytorch/valid/images/1313d19e163e93a4_jpg.rf.8a1c4fa5cf740c1aca2a8204bc586fc6.jpg: 1280x1280 (no detections), 923.8ms\n",
            "image 16/90 /content/drive/MyDrive/ColabNotebooks/data_combined/dataset1/OrangeDetection.v1i.yolov5pytorch/valid/images/151a3ab9690e999a_jpg.rf.d613b536ca254b78e279488a493d3045.jpg: 1280x1280 1 orange, 938.1ms\n",
            "image 17/90 /content/drive/MyDrive/ColabNotebooks/data_combined/dataset1/OrangeDetection.v1i.yolov5pytorch/valid/images/1934f1734662b9fa_jpg.rf.5b9b5dde01fbe7eb165a85fdeb91e7a4.jpg: 1280x1280 6 oranges, 982.4ms\n",
            "image 18/90 /content/drive/MyDrive/ColabNotebooks/data_combined/dataset1/OrangeDetection.v1i.yolov5pytorch/valid/images/1b5540ffbbaed696_jpg.rf.82f17c1c9fecdef8c6c60321473ba3bd.jpg: 1280x1280 16 oranges, 610.2ms\n",
            "image 19/90 /content/drive/MyDrive/ColabNotebooks/data_combined/dataset1/OrangeDetection.v1i.yolov5pytorch/valid/images/1d451fd3ca41cee3_jpg.rf.0a2afe95c21c15c0fccb75295d4cbd0e.jpg: 1280x1280 5 oranges, 664.4ms\n",
            "image 20/90 /content/drive/MyDrive/ColabNotebooks/data_combined/dataset1/OrangeDetection.v1i.yolov5pytorch/valid/images/204c2c346c4b08ce_jpg.rf.61ae357f89a3e4b36efe80e3cb3badb1.jpg: 1280x1280 34 oranges, 839.6ms\n",
            "image 21/90 /content/drive/MyDrive/ColabNotebooks/data_combined/dataset1/OrangeDetection.v1i.yolov5pytorch/valid/images/20c34a4a1cca43a3_jpg.rf.f35be1f4ce010f216269608b2384d76b.jpg: 1280x1280 24 oranges, 632.3ms\n",
            "image 22/90 /content/drive/MyDrive/ColabNotebooks/data_combined/dataset1/OrangeDetection.v1i.yolov5pytorch/valid/images/20f5e63d56add5de_jpg.rf.7a166db137a28301ce7941beef693801.jpg: 1280x1280 35 oranges, 584.2ms\n",
            "image 23/90 /content/drive/MyDrive/ColabNotebooks/data_combined/dataset1/OrangeDetection.v1i.yolov5pytorch/valid/images/21e579dcedbb3af7_jpg.rf.7d813a64e1182d911ceb79f8d517d017.jpg: 1280x1280 24 oranges, 666.5ms\n",
            "image 24/90 /content/drive/MyDrive/ColabNotebooks/data_combined/dataset1/OrangeDetection.v1i.yolov5pytorch/valid/images/2292cbc3d95dff5e_jpg.rf.75b7510cb60aa2857d6798c4d86136ca.jpg: 1280x1280 25 oranges, 638.5ms\n",
            "image 25/90 /content/drive/MyDrive/ColabNotebooks/data_combined/dataset1/OrangeDetection.v1i.yolov5pytorch/valid/images/2326c250afa5bbc5_jpg.rf.78cb12575af90bfcf25971596773adbe.jpg: 1280x1280 11 oranges, 907.5ms\n",
            "image 26/90 /content/drive/MyDrive/ColabNotebooks/data_combined/dataset1/OrangeDetection.v1i.yolov5pytorch/valid/images/238f53830be9a4a1_jpg.rf.14d7c1228d4300d7314208d2cad89dfb.jpg: 1280x1280 (no detections), 898.0ms\n",
            "image 27/90 /content/drive/MyDrive/ColabNotebooks/data_combined/dataset1/OrangeDetection.v1i.yolov5pytorch/valid/images/26464d181209ae4e_jpg.rf.01cf2e5a22bd243411622888ca456bd7.jpg: 1280x1280 1 orange, 621.5ms\n",
            "image 28/90 /content/drive/MyDrive/ColabNotebooks/data_combined/dataset1/OrangeDetection.v1i.yolov5pytorch/valid/images/265cbbb440530261_jpg.rf.dfc68c52f7c394a2763f969c530bca0e.jpg: 1280x1280 68 oranges, 658.1ms\n",
            "image 29/90 /content/drive/MyDrive/ColabNotebooks/data_combined/dataset1/OrangeDetection.v1i.yolov5pytorch/valid/images/296dcc04e67d488d_jpg.rf.317b67cebd0c0d59f70a591adb0bfff5.jpg: 1280x1280 1 orange, 654.8ms\n",
            "image 30/90 /content/drive/MyDrive/ColabNotebooks/data_combined/dataset1/OrangeDetection.v1i.yolov5pytorch/valid/images/296ea6156a79936b_jpg.rf.147b2a2abd7bfd79e039e0b3c76cb50a.jpg: 1280x1280 4 oranges, 628.1ms\n",
            "image 31/90 /content/drive/MyDrive/ColabNotebooks/data_combined/dataset1/OrangeDetection.v1i.yolov5pytorch/valid/images/2b591979d9a8c9f7_jpg.rf.fd5a830688a283ab96131ac9218d6879.jpg: 1280x1280 7 oranges, 626.4ms\n",
            "image 32/90 /content/drive/MyDrive/ColabNotebooks/data_combined/dataset1/OrangeDetection.v1i.yolov5pytorch/valid/images/2c1caf580d42f649_jpg.rf.31947c008263153f71b10600369c9512.jpg: 1280x1280 59 oranges, 641.2ms\n",
            "image 33/90 /content/drive/MyDrive/ColabNotebooks/data_combined/dataset1/OrangeDetection.v1i.yolov5pytorch/valid/images/2e61147bc62c949b_jpg.rf.68cb619754b3f0971fab5a00068ef718.jpg: 1280x1280 82 oranges, 748.5ms\n",
            "image 34/90 /content/drive/MyDrive/ColabNotebooks/data_combined/dataset1/OrangeDetection.v1i.yolov5pytorch/valid/images/2ee4719adf087290_jpg.rf.d46965369ada118e249b452f9f23d527.jpg: 1280x1280 3 oranges, 668.0ms\n",
            "image 35/90 /content/drive/MyDrive/ColabNotebooks/data_combined/dataset1/OrangeDetection.v1i.yolov5pytorch/valid/images/354a38aedde007a2_jpg.rf.bab9d35a9d2d46505819daad0a0b649a.jpg: 1280x1280 1 orange, 912.7ms\n",
            "image 36/90 /content/drive/MyDrive/ColabNotebooks/data_combined/dataset1/OrangeDetection.v1i.yolov5pytorch/valid/images/366bb8da949754e8_jpg.rf.156ed8e6b52eca984e2b9fa6a0195687.jpg: 1280x1280 49 oranges, 863.9ms\n",
            "image 37/90 /content/drive/MyDrive/ColabNotebooks/data_combined/dataset1/OrangeDetection.v1i.yolov5pytorch/valid/images/44e7f5162ab3146a_jpg.rf.957ad668cce5bd8543b424c8fee61486.jpg: 1280x1280 14 oranges, 693.7ms\n",
            "image 38/90 /content/drive/MyDrive/ColabNotebooks/data_combined/dataset1/OrangeDetection.v1i.yolov5pytorch/valid/images/48f7b755f04fafe4_jpg.rf.bc2439609b2bae4895a915b6a8c59db2.jpg: 1280x1280 16 oranges, 682.4ms\n",
            "image 39/90 /content/drive/MyDrive/ColabNotebooks/data_combined/dataset1/OrangeDetection.v1i.yolov5pytorch/valid/images/4f40e8744ad44c68_jpg.rf.98d25d4c86e83c9726a4c4b235cf5545.jpg: 1280x1280 41 oranges, 614.7ms\n",
            "image 40/90 /content/drive/MyDrive/ColabNotebooks/data_combined/dataset1/OrangeDetection.v1i.yolov5pytorch/valid/images/4f942df7693667ce_jpg.rf.6e0b80904eb98e6956991e80a78f03b1.jpg: 1280x1280 31 oranges, 756.4ms\n",
            "image 41/90 /content/drive/MyDrive/ColabNotebooks/data_combined/dataset1/OrangeDetection.v1i.yolov5pytorch/valid/images/5033b89b55cf6cc0_jpg.rf.88e604c593e928e158f3005836a3a718.jpg: 1280x1280 18 oranges, 916.8ms\n",
            "image 42/90 /content/drive/MyDrive/ColabNotebooks/data_combined/dataset1/OrangeDetection.v1i.yolov5pytorch/valid/images/59bc584bb13972c2_jpg.rf.ccbe174c6f7df0fa6474320c5a943b22.jpg: 1280x1280 2 oranges, 675.1ms\n",
            "image 43/90 /content/drive/MyDrive/ColabNotebooks/data_combined/dataset1/OrangeDetection.v1i.yolov5pytorch/valid/images/5fafb74fae70df30_jpg.rf.850a727a9eecade4cecd88fca0b36648.jpg: 1280x1280 3 oranges, 704.5ms\n",
            "image 44/90 /content/drive/MyDrive/ColabNotebooks/data_combined/dataset1/OrangeDetection.v1i.yolov5pytorch/valid/images/64eb2a95572dceb9_jpg.rf.e99d7d35edda18dd9d9d8edfad3d8b5c.jpg: 1280x1280 (no detections), 884.4ms\n",
            "image 45/90 /content/drive/MyDrive/ColabNotebooks/data_combined/dataset1/OrangeDetection.v1i.yolov5pytorch/valid/images/6c5dbeaa261e3fa7_jpg.rf.dc0bc5f2ba98e70fa53526427e868003.jpg: 1280x1280 135 oranges, 879.7ms\n",
            "image 46/90 /content/drive/MyDrive/ColabNotebooks/data_combined/dataset1/OrangeDetection.v1i.yolov5pytorch/valid/images/702f8c8ebbdda5fc_jpg.rf.cf18b276cbeae434a6649e4a10a4ed08.jpg: 1280x1280 (no detections), 670.7ms\n",
            "image 47/90 /content/drive/MyDrive/ColabNotebooks/data_combined/dataset1/OrangeDetection.v1i.yolov5pytorch/valid/images/708919dff4152c6a_jpg.rf.751fdd7552f3ce4e921a6cd78f56ee66.jpg: 1280x1280 4 oranges, 639.7ms\n",
            "image 48/90 /content/drive/MyDrive/ColabNotebooks/data_combined/dataset1/OrangeDetection.v1i.yolov5pytorch/valid/images/7243bb39ae8d770d_jpg.rf.212c80857befce3e4b569cf85e210366.jpg: 1280x1280 2 oranges, 672.3ms\n",
            "image 49/90 /content/drive/MyDrive/ColabNotebooks/data_combined/dataset1/OrangeDetection.v1i.yolov5pytorch/valid/images/72e80678e4f860f4_jpg.rf.5ca1a2c89b4715171e76a578ac0eea31.jpg: 1280x1280 30 oranges, 618.9ms\n",
            "image 50/90 /content/drive/MyDrive/ColabNotebooks/data_combined/dataset1/OrangeDetection.v1i.yolov5pytorch/valid/images/74b36bc9d075ef86_jpg.rf.2ec8466901356652678f7cccffafb598.jpg: 1280x1280 29 oranges, 617.8ms\n",
            "image 51/90 /content/drive/MyDrive/ColabNotebooks/data_combined/dataset1/OrangeDetection.v1i.yolov5pytorch/valid/images/751f27958923e158_jpg.rf.7465fd8a2bd9a6d9df41dedbfca0fde7.jpg: 1280x1280 46 oranges, 695.5ms\n",
            "image 52/90 /content/drive/MyDrive/ColabNotebooks/data_combined/dataset1/OrangeDetection.v1i.yolov5pytorch/valid/images/777abf02bcd7a002_jpg.rf.2bd4ba9b0a89878a560540aab8f88f29.jpg: 1280x1280 18 oranges, 683.8ms\n",
            "image 53/90 /content/drive/MyDrive/ColabNotebooks/data_combined/dataset1/OrangeDetection.v1i.yolov5pytorch/valid/images/784f9787d6af087d_jpg.rf.5681b09d54fd41c972ffbf2c1cd36cd1.jpg: 1280x1280 1 orange, 842.8ms\n",
            "image 54/90 /content/drive/MyDrive/ColabNotebooks/data_combined/dataset1/OrangeDetection.v1i.yolov5pytorch/valid/images/7b8dc40104f0dceb_jpg.rf.82cf02d2f2e16423aedf02863ef27f01.jpg: 1280x1280 53 oranges, 944.1ms\n",
            "image 55/90 /content/drive/MyDrive/ColabNotebooks/data_combined/dataset1/OrangeDetection.v1i.yolov5pytorch/valid/images/7ca0f9adfa1a4412_jpg.rf.f5e3708ca2eca160c27c617ab63f4c01.jpg: 1280x1280 5 oranges, 868.1ms\n",
            "image 56/90 /content/drive/MyDrive/ColabNotebooks/data_combined/dataset1/OrangeDetection.v1i.yolov5pytorch/valid/images/7eeee33e8caf799a_jpg.rf.1790ad8db8b25dac7e7c86923d5ebb99.jpg: 1280x1280 17 oranges, 633.2ms\n",
            "image 57/90 /content/drive/MyDrive/ColabNotebooks/data_combined/dataset1/OrangeDetection.v1i.yolov5pytorch/valid/images/815be5b979836c7d_jpg.rf.2fda54a39a89ce780394f038078f1611.jpg: 1280x1280 8 oranges, 586.6ms\n",
            "image 58/90 /content/drive/MyDrive/ColabNotebooks/data_combined/dataset1/OrangeDetection.v1i.yolov5pytorch/valid/images/89df2001c7195607_jpg.rf.464ca8674d38274989f646c9e127c413.jpg: 1280x1280 13 oranges, 719.2ms\n",
            "image 59/90 /content/drive/MyDrive/ColabNotebooks/data_combined/dataset1/OrangeDetection.v1i.yolov5pytorch/valid/images/8b918837d1c830d8_jpg.rf.a846f5d3f3a1a515c93b87be85767f4a.jpg: 1280x1280 25 oranges, 618.4ms\n",
            "image 60/90 /content/drive/MyDrive/ColabNotebooks/data_combined/dataset1/OrangeDetection.v1i.yolov5pytorch/valid/images/8f2c5f473eb86a50_jpg.rf.b25beba43b33a95d0c46c4a93157d202.jpg: 1280x1280 3 oranges, 622.2ms\n",
            "image 61/90 /content/drive/MyDrive/ColabNotebooks/data_combined/dataset1/OrangeDetection.v1i.yolov5pytorch/valid/images/90f13cdac7ede465_jpg.rf.ab08c1cbaee655595f68b50547a6c6b8.jpg: 1280x1280 15 oranges, 705.1ms\n",
            "image 62/90 /content/drive/MyDrive/ColabNotebooks/data_combined/dataset1/OrangeDetection.v1i.yolov5pytorch/valid/images/90fe62356fc7bee7_jpg.rf.717a0c8ae91f0f231d3674a0c1fc962a.jpg: 1280x1280 17 oranges, 678.6ms\n",
            "image 63/90 /content/drive/MyDrive/ColabNotebooks/data_combined/dataset1/OrangeDetection.v1i.yolov5pytorch/valid/images/95e96c3598e7f610_jpg.rf.558c8c2fccce2343063f4a875bec55ad.jpg: 1280x1280 23 oranges, 632.6ms\n",
            "image 64/90 /content/drive/MyDrive/ColabNotebooks/data_combined/dataset1/OrangeDetection.v1i.yolov5pytorch/valid/images/9fba9da1b34dad96_jpg.rf.814880dbb9790f4dfc0e3a779ad715d2.jpg: 1280x1280 4 oranges, 875.9ms\n",
            "image 65/90 /content/drive/MyDrive/ColabNotebooks/data_combined/dataset1/OrangeDetection.v1i.yolov5pytorch/valid/images/a0c0f3a12681dff9_jpg.rf.b08e55cb22c21df6f3a5b7c25634654a.jpg: 1280x1280 5 oranges, 932.1ms\n",
            "image 66/90 /content/drive/MyDrive/ColabNotebooks/data_combined/dataset1/OrangeDetection.v1i.yolov5pytorch/valid/images/aa107b6577deacc5_jpg.rf.532428f9a26e6957e76b45efc96e29eb.jpg: 1280x1280 50 oranges, 635.8ms\n",
            "image 67/90 /content/drive/MyDrive/ColabNotebooks/data_combined/dataset1/OrangeDetection.v1i.yolov5pytorch/valid/images/b041f14427de5cc3_jpg.rf.c46f27dfe24a673b7c3018ba1ed28804.jpg: 1280x1280 4 oranges, 696.5ms\n",
            "image 68/90 /content/drive/MyDrive/ColabNotebooks/data_combined/dataset1/OrangeDetection.v1i.yolov5pytorch/valid/images/b2108551f1d3ba96_jpg.rf.f1891e3d71d8f7d06e394b3945372de0.jpg: 1280x1280 13 oranges, 617.4ms\n",
            "image 69/90 /content/drive/MyDrive/ColabNotebooks/data_combined/dataset1/OrangeDetection.v1i.yolov5pytorch/valid/images/b4e511a039dce13e_jpg.rf.2d331b3e5a70ee67251d445d3c0bc670.jpg: 1280x1280 2 oranges, 692.5ms\n",
            "image 70/90 /content/drive/MyDrive/ColabNotebooks/data_combined/dataset1/OrangeDetection.v1i.yolov5pytorch/valid/images/bc7796541e388be6_jpg.rf.daecf593b53e977857f0f61ee5625024.jpg: 1280x1280 5 oranges, 659.1ms\n",
            "image 71/90 /content/drive/MyDrive/ColabNotebooks/data_combined/dataset1/OrangeDetection.v1i.yolov5pytorch/valid/images/bc952c5586850343_jpg.rf.a361dd82d0cc0de815cc235620e33b87.jpg: 1280x1280 3 oranges, 677.6ms\n",
            "image 72/90 /content/drive/MyDrive/ColabNotebooks/data_combined/dataset1/OrangeDetection.v1i.yolov5pytorch/valid/images/bf8bdff451d3c72d_jpg.rf.38a7ee3a0665064804d6d925265d33d3.jpg: 1280x1280 83 oranges, 679.2ms\n",
            "image 73/90 /content/drive/MyDrive/ColabNotebooks/data_combined/dataset1/OrangeDetection.v1i.yolov5pytorch/valid/images/c27b9897fb8bca68_jpg.rf.9eee2c250d32795786fd624199d30b1e.jpg: 1280x1280 1 orange, 862.4ms\n",
            "image 74/90 /content/drive/MyDrive/ColabNotebooks/data_combined/dataset1/OrangeDetection.v1i.yolov5pytorch/valid/images/ca2d44da136157dd_jpg.rf.0877481f6e3dd30da141bcb561071ea8.jpg: 1280x1280 (no detections), 882.1ms\n",
            "image 75/90 /content/drive/MyDrive/ColabNotebooks/data_combined/dataset1/OrangeDetection.v1i.yolov5pytorch/valid/images/cbfbaad50954de39_jpg.rf.2cc9a4ffb74d05b949fee5c7c83e0815.jpg: 1280x1280 15 oranges, 684.5ms\n",
            "image 76/90 /content/drive/MyDrive/ColabNotebooks/data_combined/dataset1/OrangeDetection.v1i.yolov5pytorch/valid/images/cfe8a663c7d42246_jpg.rf.0166435f47c3b5afb2d49b41b9b74952.jpg: 1280x1280 2 oranges, 634.7ms\n",
            "image 77/90 /content/drive/MyDrive/ColabNotebooks/data_combined/dataset1/OrangeDetection.v1i.yolov5pytorch/valid/images/d13d93c3843d6036_jpg.rf.a89bc8e1e2e24351a4b06bd1cd8ef2e0.jpg: 1280x1280 2 oranges, 831.4ms\n",
            "image 78/90 /content/drive/MyDrive/ColabNotebooks/data_combined/dataset1/OrangeDetection.v1i.yolov5pytorch/valid/images/d22fa4ad58df192e_jpg.rf.e4231e085ffc970100f9f16f04fa61db.jpg: 1280x1280 21 oranges, 654.4ms\n",
            "image 79/90 /content/drive/MyDrive/ColabNotebooks/data_combined/dataset1/OrangeDetection.v1i.yolov5pytorch/valid/images/d7535fa0e364d4b0_jpg.rf.00c161583515f7b534baee5a1a121dce.jpg: 1280x1280 1 orange, 651.1ms\n",
            "image 80/90 /content/drive/MyDrive/ColabNotebooks/data_combined/dataset1/OrangeDetection.v1i.yolov5pytorch/valid/images/db0054f721a27f51_jpg.rf.f1de105f572c97f983096c409a3e69e4.jpg: 1280x1280 5 oranges, 638.0ms\n",
            "image 81/90 /content/drive/MyDrive/ColabNotebooks/data_combined/dataset1/OrangeDetection.v1i.yolov5pytorch/valid/images/dd23b4440e3612ca_jpg.rf.471dd41ae06d0df74afae68b0f84b305.jpg: 1280x1280 18 oranges, 651.6ms\n",
            "image 82/90 /content/drive/MyDrive/ColabNotebooks/data_combined/dataset1/OrangeDetection.v1i.yolov5pytorch/valid/images/dee637f89f3cfa08_jpg.rf.3defa9bbe2016602e42ba58adfe1ea71.jpg: 1280x1280 7 oranges, 664.7ms\n",
            "image 83/90 /content/drive/MyDrive/ColabNotebooks/data_combined/dataset1/OrangeDetection.v1i.yolov5pytorch/valid/images/e2567dd988ce6fff_jpg.rf.d328d0ca431e3873804b6f3872ba0e2d.jpg: 1280x1280 1 orange, 893.3ms\n",
            "image 84/90 /content/drive/MyDrive/ColabNotebooks/data_combined/dataset1/OrangeDetection.v1i.yolov5pytorch/valid/images/e3214fceb5cc1e6e_jpg.rf.33f9644a1e80d93747cebe32df6225d3.jpg: 1280x1280 5 oranges, 898.8ms\n",
            "image 85/90 /content/drive/MyDrive/ColabNotebooks/data_combined/dataset1/OrangeDetection.v1i.yolov5pytorch/valid/images/e4a6474363e26441_jpg.rf.ed3895ca9f04190a4e6efaf68b743471.jpg: 1280x1280 (no detections), 643.1ms\n",
            "image 86/90 /content/drive/MyDrive/ColabNotebooks/data_combined/dataset1/OrangeDetection.v1i.yolov5pytorch/valid/images/e8f58c8658787a8a_jpg.rf.01db789e9e03ea36b789179a5b69c500.jpg: 1280x1280 69 oranges, 668.8ms\n",
            "image 87/90 /content/drive/MyDrive/ColabNotebooks/data_combined/dataset1/OrangeDetection.v1i.yolov5pytorch/valid/images/ec65ba7556943948_jpg.rf.dde90b1df662345ac8d1c17027c1dd63.jpg: 1280x1280 6 oranges, 696.1ms\n",
            "image 88/90 /content/drive/MyDrive/ColabNotebooks/data_combined/dataset1/OrangeDetection.v1i.yolov5pytorch/valid/images/f18cd6a3357a4b4c_jpg.rf.0f0e8ba1a66f7cdf42d092c00ac99284.jpg: 1280x1280 19 oranges, 692.9ms\n",
            "image 89/90 /content/drive/MyDrive/ColabNotebooks/data_combined/dataset1/OrangeDetection.v1i.yolov5pytorch/valid/images/f87ce03870ef7d31_jpg.rf.f9b57c1e1e640419f40de84c27d3ee2b.jpg: 1280x1280 13 oranges, 905.0ms\n",
            "image 90/90 /content/drive/MyDrive/ColabNotebooks/data_combined/dataset1/OrangeDetection.v1i.yolov5pytorch/valid/images/fcdcdfa19ed6046e_jpg.rf.d5d2dccaa8a49779ed803c8570fb0275.jpg: 1280x1280 (no detections), 903.4ms\n",
            "Speed: 14.3ms pre-process, 726.3ms inference, 2.2ms NMS per image at shape (1, 3, 1280, 1280)\n",
            "Results saved to \u001b[1mruns/detect/exp\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python /content/yolov5/detect.py --weights /content/drive/MyDrive/ColabNotebooks/best1.pt --img 1280 --conf 0.1 --source /content/drive/MyDrive/ColabNotebooks/data_combined/dataset2/cropload.v2i.yolov5pytorch/valid/images"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "95VSJL5DApCw",
        "outputId": "68bc5806-f621-48af-cfb1-e4f2e20959fc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/content/drive/MyDrive/ColabNotebooks/best1.pt'], source=/content/drive/MyDrive/ColabNotebooks/data_combined/dataset2/cropload.v2i.yolov5pytorch/valid/images, data=data/coco128.yaml, imgsz=[1280, 1280], conf_thres=0.1, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_csv=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
            "YOLOv5 🚀 v7.0-304-g22361691 Python-3.10.12 torch-2.2.1+cu121 CPU\n",
            "\n",
            "Fusing layers... \n",
            "Model summary: 157 layers, 1760518 parameters, 0 gradients, 4.1 GFLOPs\n",
            "image 1/10 /content/drive/MyDrive/ColabNotebooks/data_combined/dataset2/cropload.v2i.yolov5pytorch/valid/images/DSC_0208_JPG_jpg.rf.9999650c3d7c439aff4a5ca18e7b6c05.jpg: 1280x1280 105 oranges, 590.9ms\n",
            "image 2/10 /content/drive/MyDrive/ColabNotebooks/data_combined/dataset2/cropload.v2i.yolov5pytorch/valid/images/IMG_8764_JPG_jpg.rf.92aaf8a66d1889ef6dee7df6a9fc9d7d.jpg: 1280x1280 43 oranges, 610.2ms\n",
            "image 3/10 /content/drive/MyDrive/ColabNotebooks/data_combined/dataset2/cropload.v2i.yolov5pytorch/valid/images/IMG_8794_JPG_jpg.rf.1a8ac6f7911184b2d63bc5fd96ea225e.jpg: 1280x1280 58 oranges, 565.1ms\n",
            "image 4/10 /content/drive/MyDrive/ColabNotebooks/data_combined/dataset2/cropload.v2i.yolov5pytorch/valid/images/IMG_8795_JPG_jpg.rf.6a4a5326dcca9633a7c88d28648dd8db.jpg: 1280x1280 57 oranges, 589.2ms\n",
            "image 5/10 /content/drive/MyDrive/ColabNotebooks/data_combined/dataset2/cropload.v2i.yolov5pytorch/valid/images/IMG_8798_JPG_jpg.rf.d972d338653c6672d42432a91fd51d54.jpg: 1280x1280 44 oranges, 885.8ms\n",
            "image 6/10 /content/drive/MyDrive/ColabNotebooks/data_combined/dataset2/cropload.v2i.yolov5pytorch/valid/images/IMG_8812_JPG_jpg.rf.9752586f1f34e901ce1d13073fce9cc1.jpg: 1280x1280 65 oranges, 690.0ms\n",
            "image 7/10 /content/drive/MyDrive/ColabNotebooks/data_combined/dataset2/cropload.v2i.yolov5pytorch/valid/images/IMG_8824_JPG_jpg.rf.3b99e02a1c866e625d58044c47626de2.jpg: 1280x1280 38 oranges, 558.8ms\n",
            "image 8/10 /content/drive/MyDrive/ColabNotebooks/data_combined/dataset2/cropload.v2i.yolov5pytorch/valid/images/IMG_8830_JPG_jpg.rf.e8f25b4110f558885383f1d499cce5b8.jpg: 1280x1280 36 oranges, 588.0ms\n",
            "image 9/10 /content/drive/MyDrive/ColabNotebooks/data_combined/dataset2/cropload.v2i.yolov5pytorch/valid/images/IMG_8838_JPG_jpg.rf.bf40bf2eb08d0e1fde5407cfffe4c8ff.jpg: 1280x1280 64 oranges, 563.4ms\n",
            "image 10/10 /content/drive/MyDrive/ColabNotebooks/data_combined/dataset2/cropload.v2i.yolov5pytorch/valid/images/p22_JPG_jpg.rf.13804f64dc1d3eacd2cc9a3d934f3615.jpg: 1280x1280 74 oranges, 633.2ms\n",
            "Speed: 10.4ms pre-process, 627.5ms inference, 2.1ms NMS per image at shape (1, 3, 1280, 1280)\n",
            "Results saved to \u001b[1mruns/detect/exp5\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python /content/yolov5/detect.py --weights /content/drive/MyDrive/ColabNotebooks/best1.pt --img 1280 --conf 0.1 --source /content/drive/MyDrive/ColabNotebooks/data_combined/dataset3/FinalDataset.v2i.yolov5pytorch/valid/images"
      ],
      "metadata": {
        "id": "1x2-FILwBArR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8bf8d52a-a762-419f-daa5-91c90f897aff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/content/drive/MyDrive/ColabNotebooks/best1.pt'], source=/content/drive/MyDrive/ColabNotebooks/data_combined/dataset3/FinalDataset.v2i.yolov5pytorch/valid/images, data=data/coco128.yaml, imgsz=[1280, 1280], conf_thres=0.1, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_csv=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
            "YOLOv5 🚀 v7.0-304-g22361691 Python-3.10.12 torch-2.2.1+cu121 CPU\n",
            "\n",
            "Fusing layers... \n",
            "Model summary: 157 layers, 1760518 parameters, 0 gradients, 4.1 GFLOPs\n",
            "image 1/15 /content/drive/MyDrive/ColabNotebooks/data_combined/dataset3/FinalDataset.v2i.yolov5pytorch/valid/images/IMG_8762_JPG.rf.c16c59c24dd93ed97f1d38b004c10703.jpg: 1280x1280 123 oranges, 878.8ms\n",
            "image 2/15 /content/drive/MyDrive/ColabNotebooks/data_combined/dataset3/FinalDataset.v2i.yolov5pytorch/valid/images/IMG_8764_JPG.rf.ec8947ff215443d30e1f84d96227a072.jpg: 1280x1280 43 oranges, 567.4ms\n",
            "image 3/15 /content/drive/MyDrive/ColabNotebooks/data_combined/dataset3/FinalDataset.v2i.yolov5pytorch/valid/images/IMG_8765_JPG.rf.ef80a4bef0875c8a6c94d83bbffc20a4.jpg: 1280x1280 41 oranges, 574.0ms\n",
            "image 4/15 /content/drive/MyDrive/ColabNotebooks/data_combined/dataset3/FinalDataset.v2i.yolov5pytorch/valid/images/IMG_8766_JPG.rf.e63840f4f639ed9ddd23e901ffcf9e74.jpg: 1280x1280 15 oranges, 616.8ms\n",
            "image 5/15 /content/drive/MyDrive/ColabNotebooks/data_combined/dataset3/FinalDataset.v2i.yolov5pytorch/valid/images/IMG_8792_JPG.rf.9a047f31dc0b73288e7a0222768d22d1.jpg: 1280x1280 22 oranges, 608.9ms\n",
            "image 6/15 /content/drive/MyDrive/ColabNotebooks/data_combined/dataset3/FinalDataset.v2i.yolov5pytorch/valid/images/IMG_8804_JPG.rf.b2ff4c06a01ad4abcfa01b977ce18052.jpg: 1280x1280 39 oranges, 570.9ms\n",
            "image 7/15 /content/drive/MyDrive/ColabNotebooks/data_combined/dataset3/FinalDataset.v2i.yolov5pytorch/valid/images/IMG_8805_JPG.rf.d7596c040c07718ae32fb1522c07db85.jpg: 1280x1280 49 oranges, 579.7ms\n",
            "image 8/15 /content/drive/MyDrive/ColabNotebooks/data_combined/dataset3/FinalDataset.v2i.yolov5pytorch/valid/images/IMG_8817_JPG.rf.995de452a77e7331fa1a7765a6d6cff4.jpg: 1280x1280 45 oranges, 578.0ms\n",
            "image 9/15 /content/drive/MyDrive/ColabNotebooks/data_combined/dataset3/FinalDataset.v2i.yolov5pytorch/valid/images/IMG_8819_JPG.rf.2de176e8254d16e90f566784280453b1.jpg: 1280x1280 23 oranges, 856.6ms\n",
            "image 10/15 /content/drive/MyDrive/ColabNotebooks/data_combined/dataset3/FinalDataset.v2i.yolov5pytorch/valid/images/IMG_8820_JPG.rf.826f620bfc95e0a29f8b01751f85d1fe.jpg: 1280x1280 24 oranges, 883.7ms\n",
            "image 11/15 /content/drive/MyDrive/ColabNotebooks/data_combined/dataset3/FinalDataset.v2i.yolov5pytorch/valid/images/IMG_8822_JPG.rf.b69cf26e58f28098c20633b1d22ed3cb.jpg: 1280x1280 28 oranges, 557.3ms\n",
            "image 12/15 /content/drive/MyDrive/ColabNotebooks/data_combined/dataset3/FinalDataset.v2i.yolov5pytorch/valid/images/IMG_8829_JPG.rf.a14369713a130d2e7d9b0576afd2108d.jpg: 1280x1280 25 oranges, 575.4ms\n",
            "image 13/15 /content/drive/MyDrive/ColabNotebooks/data_combined/dataset3/FinalDataset.v2i.yolov5pytorch/valid/images/IMG_8830_JPG.rf.d4b604cbe68812cff132069b3f59b583.jpg: 1280x1280 36 oranges, 564.7ms\n",
            "image 14/15 /content/drive/MyDrive/ColabNotebooks/data_combined/dataset3/FinalDataset.v2i.yolov5pytorch/valid/images/IMG_8832_JPG.rf.f98f28cbc818d94f25c42d1dce9a5704.jpg: 1280x1280 56 oranges, 645.4ms\n",
            "image 15/15 /content/drive/MyDrive/ColabNotebooks/data_combined/dataset3/FinalDataset.v2i.yolov5pytorch/valid/images/IMG_8838_JPG.rf.ca359b7c96367a7c0a0b09d67318735b.jpg: 1280x1280 72 oranges, 567.2ms\n",
            "Speed: 14.4ms pre-process, 641.7ms inference, 2.2ms NMS per image at shape (1, 3, 1280, 1280)\n",
            "Results saved to \u001b[1mruns/detect/exp6\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python /content/yolov5/detect.py --weights /content/drive/MyDrive/ColabNotebooks/best1.pt --img 1280 --conf 0.1 --source /content/drive/MyDrive/ColabNotebooks/test/video"
      ],
      "metadata": {
        "id": "aavOB_26BDbY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from PIL import Image\n",
        "\n",
        "# Function to crop an image into 4 pieces\n",
        "def crop_image(image):\n",
        "    width, height = image.size\n",
        "    piece_width = width // 2\n",
        "    piece_height = height // 2\n",
        "    pieces = []\n",
        "    for j in range(2):\n",
        "        for i in range(2):\n",
        "            box = (i * piece_width, j * piece_height, (i + 1) * piece_width, (j + 1) * piece_height)\n",
        "            piece = image.crop(box)\n",
        "            pieces.append(piece)\n",
        "    return pieces\n",
        "\n",
        "# Path to the directory containing the input images\n",
        "input_directory = \"/content/drive/MyDrive/ColabNotebooks/test/imagesinput\"\n",
        "output_directory = \"/content/drive/MyDrive/ColabNotebooks/test/imagesdecoupees\"\n",
        "\n",
        "# Iterate through all images in the directory\n",
        "for filename in os.listdir(input_directory):\n",
        "    if filename.endswith(\".jpg\") or filename.endswith(\".png\") or filename.endswith(\".JPG\"): # Filter image files\n",
        "        # Load the image\n",
        "        image_path = os.path.join(input_directory, filename)\n",
        "        image = Image.open(image_path)\n",
        "\n",
        "        # Crop the image into pieces\n",
        "        pieces = crop_image(image)\n",
        "\n",
        "        # Save the pieces in the output directory\n",
        "        for idx, piece in enumerate(pieces):\n",
        "            piece_filename = f\"{filename.split('.')[0]}%piece{idx}.JPG\"\n",
        "            piece_path = os.path.join(output_directory, piece_filename)\n",
        "            piece.save(piece_path)\n",
        "\n",
        "            # Display the positions of each piece\n",
        "            print(f\"Position of {piece_filename}: {idx % 2}, {idx // 2}\")\n",
        "\n",
        "print(\"Cropping completed.\")\n"
      ],
      "metadata": {
        "id": "_4vg7JS0BF5a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ffd309e2-a21b-4da0-eb93-a1c8bb06cead"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Position of 2446309%piece0.JPG: 0, 0\n",
            "Position of 2446309%piece1.JPG: 1, 0\n",
            "Position of 2446309%piece2.JPG: 0, 1\n",
            "Position of 2446309%piece3.JPG: 1, 1\n",
            "Cropping completed.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python /content/yolov5/detect.py  --weights /content/drive/MyDrive/ColabNotebooks/best1.pt  --img 1280 --conf 0.1 --source /content/drive/MyDrive/ColabNotebooks/test/imagesdecoupees"
      ],
      "metadata": {
        "id": "a1lU6CDcBIWk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "590ae4a8-7dd2-40a2-b8ed-eb6b5c75be2d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/content/drive/MyDrive/ColabNotebooks/best1.pt'], source=/content/drive/MyDrive/ColabNotebooks/test/imagesdecoupees, data=data/coco128.yaml, imgsz=[1280, 1280], conf_thres=0.1, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_csv=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
            "YOLOv5 🚀 v7.0-304-g22361691 Python-3.10.12 torch-2.2.1+cu121 CPU\n",
            "\n",
            "Fusing layers... \n",
            "Model summary: 157 layers, 1760518 parameters, 0 gradients, 4.1 GFLOPs\n",
            "image 1/4 /content/drive/MyDrive/ColabNotebooks/test/imagesdecoupees/2446309%piece0.JPG: 736x1280 73 oranges, 511.9ms\n",
            "image 2/4 /content/drive/MyDrive/ColabNotebooks/test/imagesdecoupees/2446309%piece1.JPG: 736x1280 7 oranges, 486.5ms\n",
            "image 3/4 /content/drive/MyDrive/ColabNotebooks/test/imagesdecoupees/2446309%piece2.JPG: 736x1280 48 oranges, 491.9ms\n",
            "image 4/4 /content/drive/MyDrive/ColabNotebooks/test/imagesdecoupees/2446309%piece3.JPG: 736x1280 37 oranges, 475.2ms\n",
            "Speed: 4.7ms pre-process, 491.4ms inference, 2.0ms NMS per image at shape (1, 3, 1280, 1280)\n",
            "Results saved to \u001b[1mruns/detect/exp7\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from PIL import Image\n",
        "\n",
        "# Function to reconstruct an image from pieces\n",
        "def reconstruct_image(pieces, output_path):\n",
        "    # Get dimensions of a piece\n",
        "    piece_width, piece_height = pieces[0].size\n",
        "\n",
        "    # Calculate dimensions of the reconstructed image\n",
        "    image_width = piece_width * 2\n",
        "    image_height = piece_height * 2\n",
        "\n",
        "    # Create a new image to reconstruct the original image\n",
        "    reconstructed_image = Image.new(\"RGB\", (image_width, image_height))\n",
        "\n",
        "    # Assemble the pieces to reconstruct the original image\n",
        "    for idx, piece in enumerate(pieces):\n",
        "        x = idx % 2\n",
        "        y = idx // 2\n",
        "        reconstructed_image.paste(piece, (x * piece_width, y * piece_height))\n",
        "\n",
        "    # Save the reconstructed image\n",
        "    reconstructed_image.save(output_path)\n",
        "\n",
        "# Path to the directory containing image pieces\n",
        "input_directory = \"/content/yolov5/runs/detect/exp7\"\n",
        "output_directory = \"/content/drive/MyDrive/ColabNotebooks/test/imagesoutput\"\n",
        "\n",
        "# Iterate through all image pieces in the directory\n",
        "image_pieces = {}\n",
        "for filename in sorted(os.listdir(input_directory)):  # Added sorted() here\n",
        "    if filename.endswith(\".jpg\") or filename.endswith(\".png\") or filename.endswith(\".JPG\"):  # Filter image files\n",
        "        # Extract the name of the original image from the piece name\n",
        "        image_name = filename.split(\"%\")[0]\n",
        "\n",
        "        # Load the image piece\n",
        "        piece_path = os.path.join(input_directory, filename)\n",
        "        piece = Image.open(piece_path)\n",
        "\n",
        "        # Add the piece to the list of pieces associated with the original image\n",
        "        if image_name not in image_pieces:\n",
        "            image_pieces[image_name] = []\n",
        "        image_pieces[image_name].append(piece)\n",
        "\n",
        "# Before reconstituting each image, sort the pieces by their intended order\n",
        "for image_name, pieces in image_pieces.items():\n",
        "    # Assuming your pieces are named with an ending number indicating their order\n",
        "    pieces_sorted = sorted(pieces, key=lambda x: int(x.filename.split('%')[-1].split('.')[0].replace('piece', '')))\n",
        "    # Output path for the reconstructed image\n",
        "    output_path = os.path.join(output_directory, f\"{image_name}%reconstructed.JPG\")\n",
        "    # Reconstruct the image with the sorted pieces and save\n",
        "    reconstruct_image(pieces_sorted, output_path)\n",
        "\n",
        "print(\"Reconstruction completed.\")\n"
      ],
      "metadata": {
        "id": "Vo9vMLo7BKkz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b024a068-4f7e-4502-948f-019a2e8b561e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reconstruction completed.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import shutil\n",
        "\n",
        "def empty_directory(directory):\n",
        "    \"\"\"\n",
        "    Vide un répertoire en supprimant tous ses fichiers et sous-répertoires.\n",
        "    Args:\n",
        "        directory (str): Chemin du répertoire à vider.\n",
        "    \"\"\"\n",
        "    for filename in os.listdir(directory):\n",
        "        file_path = os.path.join(directory, filename)\n",
        "        try:\n",
        "            if os.path.isfile(file_path) or os.path.islink(file_path):\n",
        "                os.unlink(file_path)\n",
        "            elif os.path.isdir(file_path):\n",
        "                shutil.rmtree(file_path)\n",
        "        except Exception as e:\n",
        "            print('Erreur lors de la suppression du fichier %s : %s' % (file_path, e))\n",
        "\n",
        "# Spécifiez les chemins des répertoires que vous souhaitez vider\n",
        "directories_to_empty = [\n",
        "    '/content/yolov5/runs/detect',\n",
        "    '/content/drive/MyDrive/ColabNotebooks/test/video',\n",
        "    '/content/drive/MyDrive/ColabNotebooks/test/imagesoutput',\n",
        "    '/content/drive/MyDrive/ColabNotebooks/test/imagesinput',\n",
        "    '/content/drive/MyDrive/ColabNotebooks/test/imagesdecoupees',\n",
        "\n",
        "    # Ajoutez d'autres répertoires au besoin\n",
        "]\n",
        "\n",
        "# Videz chaque répertoire spécifié\n",
        "for directory in directories_to_empty:\n",
        "    print(\"Vidage du répertoire :\", directory)\n",
        "    empty_directory(directory)\n"
      ],
      "metadata": {
        "id": "2VbU03nIBPQ3"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}