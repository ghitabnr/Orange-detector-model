{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNI0noU8w3VtyKaurlgwHqk",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ghitabnr/Orange-detector-model/blob/main/main.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ddAIvnzAtTn_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4e39cd55-e48f-46f7-8a55-34b96e4cfb41"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting fastapi\n",
            "  Downloading fastapi-0.110.1-py3-none-any.whl (91 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/91.9 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━\u001b[0m \u001b[32m61.4/91.9 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m91.9/91.9 kB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting kaleido\n",
            "  Downloading kaleido-0.2.1-py2.py3-none-manylinux1_x86_64.whl (79.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.9/79.9 MB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting python-multipart\n",
            "  Downloading python_multipart-0.0.9-py3-none-any.whl (22 kB)\n",
            "Collecting uvicorn\n",
            "  Downloading uvicorn-0.29.0-py3-none-any.whl (60 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.8/60.8 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from fastapi) (2.6.4)\n",
            "Collecting starlette<0.38.0,>=0.37.2 (from fastapi)\n",
            "  Downloading starlette-0.37.2-py3-none-any.whl (71 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.9/71.9 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from fastapi) (4.10.0)\n",
            "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.10/dist-packages (from uvicorn) (8.1.7)\n",
            "Collecting h11>=0.8 (from uvicorn)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4->fastapi) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.16.3 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4->fastapi) (2.16.3)\n",
            "Requirement already satisfied: anyio<5,>=3.4.0 in /usr/local/lib/python3.10/dist-packages (from starlette<0.38.0,>=0.37.2->fastapi) (3.7.1)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.4.0->starlette<0.38.0,>=0.37.2->fastapi) (3.6)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.4.0->starlette<0.38.0,>=0.37.2->fastapi) (1.3.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.4.0->starlette<0.38.0,>=0.37.2->fastapi) (1.2.0)\n",
            "Installing collected packages: kaleido, python-multipart, h11, uvicorn, starlette, fastapi\n",
            "Successfully installed fastapi-0.110.1 h11-0.14.0 kaleido-0.2.1 python-multipart-0.0.9 starlette-0.37.2 uvicorn-0.29.0\n"
          ]
        }
      ],
      "source": [
        "pip install fastapi kaleido python-multipart uvicorn"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/ultralytics/yolov5\n",
        "%cd yolov5\n",
        "%pip install -r requirements.txt\n",
        "%pip install -q roboflow\n",
        "import torch\n",
        "import os\n",
        "from IPython.display import Image, clear_output\n",
        "print(f\"setup complete using torch {torch.__version__}({torch.cuda.get_device_properties(0).name if torch.cuda.is_available()else 'cpu'})\")\n"
      ],
      "metadata": {
        "id": "NTMdVsphtckA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3dc3c4a0-8e17-4060-b9fa-318212da73f6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'yolov5'...\n",
            "remote: Enumerating objects: 16525, done.\u001b[K\n",
            "remote: Total 16525 (delta 0), reused 0 (delta 0), pack-reused 16525\u001b[K\n",
            "Receiving objects: 100% (16525/16525), 15.05 MiB | 19.71 MiB/s, done.\n",
            "Resolving deltas: 100% (11355/11355), done.\n",
            "/content/yolov5\n",
            "Collecting gitpython>=3.1.30 (from -r requirements.txt (line 5))\n",
            "  Downloading GitPython-3.1.43-py3-none-any.whl (207 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.3/207.3 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: matplotlib>=3.3 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 6)) (3.7.1)\n",
            "Requirement already satisfied: numpy>=1.23.5 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 7)) (1.25.2)\n",
            "Requirement already satisfied: opencv-python>=4.1.1 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 8)) (4.8.0.76)\n",
            "Requirement already satisfied: Pillow>=9.4.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 9)) (9.4.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 10)) (5.9.5)\n",
            "Requirement already satisfied: PyYAML>=5.3.1 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 11)) (6.0.1)\n",
            "Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 12)) (2.31.0)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 13)) (1.11.4)\n",
            "Collecting thop>=0.1.1 (from -r requirements.txt (line 14))\n",
            "  Downloading thop-0.1.1.post2209072238-py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 15)) (2.2.1+cu121)\n",
            "Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 16)) (0.17.1+cu121)\n",
            "Requirement already satisfied: tqdm>=4.64.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 17)) (4.66.2)\n",
            "Collecting ultralytics>=8.0.232 (from -r requirements.txt (line 18))\n",
            "  Downloading ultralytics-8.1.43-py3-none-any.whl (749 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m749.5/749.5 kB\u001b[0m \u001b[31m46.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 27)) (2.0.3)\n",
            "Requirement already satisfied: seaborn>=0.11.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 28)) (0.13.1)\n",
            "Requirement already satisfied: setuptools>=65.5.1 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 42)) (67.7.2)\n",
            "Requirement already satisfied: wheel>=0.38.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 50)) (0.43.0)\n",
            "Collecting gitdb<5,>=4.0.1 (from gitpython>=3.1.30->-r requirements.txt (line 5))\n",
            "  Downloading gitdb-4.0.11-py3-none-any.whl (62 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3->-r requirements.txt (line 6)) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3->-r requirements.txt (line 6)) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3->-r requirements.txt (line 6)) (4.50.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3->-r requirements.txt (line 6)) (1.4.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3->-r requirements.txt (line 6)) (24.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3->-r requirements.txt (line 6)) (3.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3->-r requirements.txt (line 6)) (2.8.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->-r requirements.txt (line 12)) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->-r requirements.txt (line 12)) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->-r requirements.txt (line 12)) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->-r requirements.txt (line 12)) (2024.2.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->-r requirements.txt (line 15)) (3.13.3)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->-r requirements.txt (line 15)) (4.10.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->-r requirements.txt (line 15)) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->-r requirements.txt (line 15)) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->-r requirements.txt (line 15)) (3.1.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->-r requirements.txt (line 15)) (2023.6.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch>=1.8.0->-r requirements.txt (line 15))\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m56.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-runtime-cu12==12.1.105 (from torch>=1.8.0->-r requirements.txt (line 15))\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.6/823.6 kB\u001b[0m \u001b[31m53.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-cupti-cu12==12.1.105 (from torch>=1.8.0->-r requirements.txt (line 15))\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m69.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cudnn-cu12==8.9.2.26 (from torch>=1.8.0->-r requirements.txt (line 15))\n",
            "  Downloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "\u001b[2K     \u001b[91m━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m204.3/731.7 MB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:01:09\u001b[0m\u001b[31mERROR: Operation cancelled by user\u001b[0m\u001b[31m\n",
            "\u001b[2K     \u001b[91m━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m204.3/731.7 MB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:01:10\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.0/72.0 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m158.3/158.3 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m178.7/178.7 kB\u001b[0m \u001b[31m12.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.8/58.8 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.1/49.1 MB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.5/54.5 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hsetup complete using torch 2.2.1+cu121(cpu)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from roboflow import Roboflow\n",
        "\n",
        "# Replace \"YOUR_API_KEY\" with your actual API key\n",
        "api_key = \"wFtaGSOH7u1ocRRARzly\"\n",
        "\n",
        "rf = Roboflow(model_format=\"yolov5\", notebook=\"ultralytics\", api_key=api_key)"
      ],
      "metadata": {
        "id": "PWFACAN0td7y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "os.environ[\"DATASET_DIRECTORY\"]= \"/content/dataset1\""
      ],
      "metadata": {
        "id": "6YWjj46Gtf6D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rf = Roboflow(api_key=\"wFtaGSOH7u1ocRRARzly\")\n",
        "project = rf.workspace(\"ozan-miooullar\").project(\"orange-detection-0u5ih\")\n",
        "dataset = project.version(1).download(\"yolov5\")"
      ],
      "metadata": {
        "id": "lk5NsbU4thjb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "07a5b9f3-82b2-4929-c7c9-7e54aafeb678"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loading Roboflow workspace...\n",
            "loading Roboflow project...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading Dataset Version Zip in /content/dataset1/Orange-Detection-1 to yolov5pytorch:: 100%|██████████| 67774/67774 [00:01<00:00, 43434.78it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Extracting Dataset Version Zip to /content/dataset1/Orange-Detection-1 in yolov5pytorch:: 100%|██████████| 5031/5031 [00:00<00:00, 5234.24it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "os.environ[\"DATASET_DIRECTORY\"]= \"/content/dataset2\""
      ],
      "metadata": {
        "id": "kv1w691ZtjPQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "rf = Roboflow(api_key=\"wFtaGSOH7u1ocRRARzly\")\n",
        "project = rf.workspace(\"new-workspace-cnsq7\").project(\"cropload\")\n",
        "dataset = project.version(2).download(\"yolov5\")\n"
      ],
      "metadata": {
        "id": "T-MMSqpBtkjU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "371459c2-537b-4991-f0f7-03bfc3349dac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loading Roboflow workspace...\n",
            "loading Roboflow project...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading Dataset Version Zip in /content/dataset2/cropload-2 to yolov5pytorch:: 100%|██████████| 74817/74817 [00:01<00:00, 46786.36it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Extracting Dataset Version Zip to /content/dataset2/cropload-2 in yolov5pytorch:: 100%|██████████| 507/507 [00:00<00:00, 1324.34it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "os.environ[\"DATASET_DIRECTORY\"]= \"/content/dataset3\""
      ],
      "metadata": {
        "id": "aAKXmGWBtmAI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "rf = Roboflow(api_key=\"wFtaGSOH7u1ocRRARzly\")\n",
        "project = rf.workspace(\"new-workspace-cnsq7\").project(\"final-dataset-f7xeq\")\n",
        "version = project.version(2)\n",
        "dataset = version.download(\"yolov5\")"
      ],
      "metadata": {
        "id": "GlVEO9u0tno3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1facec2b-d6c4-4e2e-e733-a46306fbd0b2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loading Roboflow workspace...\n",
            "loading Roboflow project...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading Dataset Version Zip in /content/dataset3/Final-Dataset-2 to yolov5pytorch:: 100%|██████████| 48444/48444 [00:03<00:00, 13935.73it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Extracting Dataset Version Zip to /content/dataset3/Final-Dataset-2 in yolov5pytorch:: 100%|██████████| 359/359 [00:00<00:00, 760.01it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mv /content/dataset3/Final-Dataset-2/test /content/dataset3/Final-Dataset-2/valid"
      ],
      "metadata": {
        "id": "_uYv9SK9tp17"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mv /content/dataset2/cropload-2/test /content/dataset2/cropload-2/valid"
      ],
      "metadata": {
        "id": "jR6ccMJ3trXp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir /content/data_combined"
      ],
      "metadata": {
        "id": "D6AeLd-5ts1E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cp -r /content/dataset1/* /content/data_combined\n",
        "!cp -r /content/dataset2/* /content/data_combined\n",
        "!cp -r /content/dataset3/* /content/data_combined"
      ],
      "metadata": {
        "id": "90c0RyTxtudB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls /content/data_combined"
      ],
      "metadata": {
        "id": "2cIrIs_gtwGl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0a1dc3c8-3b9b-4130-c789-a0fdb6f483e9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cropload-2  Final-Dataset-2  Orange-Detection-1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Lire le contenu du premier fichier data.yaml\n",
        "with open('/content/data_combined/Orange-Detection-1/data.yaml', 'r') as file1:\n",
        "    data1_content = file1.read()\n",
        "\n",
        "# Lire le contenu du deuxième fichier data.yaml\n",
        "with open('/content/data_combined/cropload-2/data.yaml', 'r') as file2:\n",
        "    data2_content = file2.read()\n",
        "\n",
        "with open('/content/data_combined/Final-Dataset-2/data.yaml', 'r') as file3:\n",
        "    data3_content = file3.read()\n",
        "# Fusionner les contenus des deux fichiers en un seul\n",
        "combined_content = data1_content + '\\n' + data2_content + '\\n' + data3_content\n",
        "\n",
        "# Écrire le contenu combiné dans un nouveau fichier data_combined.yaml\n",
        "with open('/content/data_combined/data_combined.yaml', 'w') as file_combined:\n",
        "    file_combined.write(combined_content)"
      ],
      "metadata": {
        "id": "B-78xpkMtyEa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python train.py --img 672 --epochs 100 --data /content/data_combined/data_combined.yaml --weights yolov5n.pt --cache\n"
      ],
      "metadata": {
        "id": "l8x7zZGut3Xw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "484bd44c-d849-4917-95b4-61c1562ceb8d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-04-05 18:00:09.192072: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-04-05 18:00:09.192159: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-04-05 18:00:09.196019: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tensorboard/compat/__init__.py\", line 42, in tf\n",
            "    from tensorboard.compat import notf  # noqa: F401\n",
            "ImportError: cannot import name 'notf' from 'tensorboard.compat' (/usr/local/lib/python3.10/dist-packages/tensorboard/compat/__init__.py)\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/yolov5/train.py\", line 81, in <module>\n",
            "    from utils.loggers import LOGGERS, Loggers\n",
            "  File \"/content/yolov5/utils/loggers/__init__.py\", line 22, in <module>\n",
            "    from torch.utils.tensorboard import SummaryWriter\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/tensorboard/__init__.py\", line 12, in <module>\n",
            "    from .writer import FileWriter, SummaryWriter  # noqa: F401\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/tensorboard/writer.py\", line 18, in <module>\n",
            "    from ._embedding import get_embedding_info, make_mat, make_sprite, make_tsv, write_pbtxt\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/tensorboard/_embedding.py\", line 9, in <module>\n",
            "    _HAS_GFILE_JOIN = hasattr(tf.io.gfile, \"join\")\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tensorboard/lazy.py\", line 65, in __getattr__\n",
            "    return getattr(load_once(self), attr_name)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tensorboard/lazy.py\", line 97, in wrapper\n",
            "    cache[arg] = f(arg)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tensorboard/lazy.py\", line 50, in load_once\n",
            "    module = load_fn()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tensorboard/compat/__init__.py\", line 45, in tf\n",
            "    import tensorflow\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tensorflow/__init__.py\", line 48, in <module>\n",
            "    from tensorflow._api.v2 import __internal__\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tensorflow/_api/v2/__internal__/__init__.py\", line 13, in <module>\n",
            "    from tensorflow._api.v2.__internal__ import feature_column\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tensorflow/_api/v2/__internal__/feature_column/__init__.py\", line 8, in <module>\n",
            "    from tensorflow.python.feature_column.feature_column_v2 import DenseColumn # line: 1983\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tensorflow/python/feature_column/feature_column_v2.py\", line 2696, in <module>\n",
            "    class EmbeddingColumn(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tensorflow/python/feature_column/feature_column_v2.py\", line 2873, in EmbeddingColumn\n",
            "    def _get_dense_tensor(self, inputs, weight_collections=None, trainable=None):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/deprecation.py\", line 390, in deprecated_wrapper\n",
            "    new_func.__signature__ = inspect.signature(func)\n",
            "  File \"/usr/lib/python3.10/inspect.py\", line 3254, in signature\n",
            "    return Signature.from_callable(obj, follow_wrapped=follow_wrapped,\n",
            "  File \"/usr/lib/python3.10/inspect.py\", line 3002, in from_callable\n",
            "    return _signature_from_callable(obj, sigcls=cls,\n",
            "  File \"/usr/lib/python3.10/inspect.py\", line 2463, in _signature_from_callable\n",
            "    return _signature_from_function(sigcls, obj,\n",
            "  File \"/usr/lib/python3.10/inspect.py\", line 2307, in _signature_from_function\n",
            "    annotations = get_annotations(func, globals=globals, locals=locals, eval_str=eval_str)\n",
            "  File \"/usr/lib/python3.10/inspect.py\", line 111, in get_annotations\n",
            "    if isinstance(obj, type):\n",
            "KeyboardInterrupt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%load_ext tensorboard\n",
        "%tensorboard --logdir runs"
      ],
      "metadata": {
        "id": "zsiJ8Jkpt5Ek",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "9d5b2024-2309-406a-8fa9-746a526a08c7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Launching TensorBoard..."
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python detect.py --weights /content/yolov5/runs/train/exp/weights/best.pt --img 672 --conf 0.1 --source /content/data_combined/Orange-Detection-1/valid/images"
      ],
      "metadata": {
        "id": "ew9WtXsTt68N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python detect.py --weights /content/yolov5/runs/train/exp/weights/best.pt --img 672 --conf 0.1 --source /content/data_combined/cropload-2/valid/images"
      ],
      "metadata": {
        "id": "pJHIuPiPt8Xi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python detect.py --weights /content/yolov5/runs/train/exp/weights/best.pt --img 672 --conf 0.1 --source /content/data_combined/Final-Dataset-2/valid/images"
      ],
      "metadata": {
        "id": "lvar4CjEt-K3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir /content/test"
      ],
      "metadata": {
        "id": "3vfVVr4ht_p0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir /content/test/imagesinput"
      ],
      "metadata": {
        "id": "7yusI4tyuBoQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir /content/test/imagesdecoupees"
      ],
      "metadata": {
        "id": "XwKDhOfDuDMX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir /content/test/imagesoutput"
      ],
      "metadata": {
        "id": "WYadW3rouEgu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir /content/test/video"
      ],
      "metadata": {
        "id": "eJXnbbEQuF_r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "VIDEO"
      ],
      "metadata": {
        "id": "csa7O0kYuJrw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python detect.py --weights /content/yolov5/runs/train/exp/weights/best.pt --img 672 --conf 0.1 --source /content/test/video/"
      ],
      "metadata": {
        "id": "5HhDtDsxuH-9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "DECOUPAGE EN **4**"
      ],
      "metadata": {
        "id": "Mn0qJrftuNgW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from PIL import Image\n",
        "\n",
        "# Function to crop an image into 4 pieces\n",
        "def crop_image(image):\n",
        "    width, height = image.size\n",
        "    piece_width = width // 2\n",
        "    piece_height = height // 2\n",
        "    pieces = []\n",
        "    for j in range(2):\n",
        "        for i in range(2):\n",
        "            box = (i * piece_width, j * piece_height, (i + 1) * piece_width, (j + 1) * piece_height)\n",
        "            piece = image.crop(box)\n",
        "            pieces.append(piece)\n",
        "    return pieces\n",
        "\n",
        "# Path to the directory containing the input images\n",
        "input_directory = \"/content/test/imagesinput\"\n",
        "output_directory = \"/content/test/imagesdecoupees\"\n",
        "\n",
        "# Iterate through all images in the directory\n",
        "for filename in os.listdir(input_directory):\n",
        "    if filename.endswith(\".jpg\") or filename.endswith(\".png\"): # Filter image files\n",
        "        # Load the image\n",
        "        image_path = os.path.join(input_directory, filename)\n",
        "        image = Image.open(image_path)\n",
        "\n",
        "        # Crop the image into pieces\n",
        "        pieces = crop_image(image)\n",
        "\n",
        "        # Save the pieces in the output directory\n",
        "        for idx, piece in enumerate(pieces):\n",
        "            piece_filename = f\"{filename.split('.')[0]}_piece{idx}.jpg\"\n",
        "            piece_path = os.path.join(output_directory, piece_filename)\n",
        "            piece.save(piece_path)\n",
        "\n",
        "            # Display the positions of each piece\n",
        "            print(f\"Position of {piece_filename}: {idx % 2}, {idx // 2}\")\n",
        "\n",
        "print(\"Cropping completed.\")\n"
      ],
      "metadata": {
        "id": "73f8-gcBuPeD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python detect.py --weights /content/yolov5/runs/train/exp/weights/best.pt --img 672 --conf 0.1 --source /content/test/imagesdecoupees"
      ],
      "metadata": {
        "id": "FXAlhSwNuRPM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from PIL import Image\n",
        "\n",
        "# Function to reconstruct an image from pieces\n",
        "def reconstruct_image(pieces, output_path):\n",
        "    # Get dimensions of a piece\n",
        "    piece_width, piece_height = pieces[0].size\n",
        "\n",
        "    # Calculate dimensions of the reconstructed image\n",
        "    image_width = piece_width * 2\n",
        "    image_height = piece_height * 2\n",
        "\n",
        "    # Create a new image to reconstruct the original image\n",
        "    reconstructed_image = Image.new(\"RGB\", (image_width, image_height))\n",
        "\n",
        "    # Assemble the pieces to reconstruct the original image\n",
        "    for idx, piece in enumerate(pieces):\n",
        "        x = idx % 2\n",
        "        y = idx // 2\n",
        "        reconstructed_image.paste(piece, (x * piece_width, y * piece_height))\n",
        "\n",
        "    # Save the reconstructed image\n",
        "    reconstructed_image.save(output_path)\n",
        "\n",
        "# Path to the directory containing image pieces\n",
        "input_directory = \"/content/yolov5/runs/detect/exp22\"\n",
        "output_directory = \"/content/test/imagesoutput\"\n",
        "\n",
        "# Iterate through all image pieces in the directory\n",
        "image_pieces = {}\n",
        "for filename in sorted(os.listdir(input_directory)):  # Added sorted() here\n",
        "    if filename.endswith(\".jpg\") or filename.endswith(\".png\"):  # Filter image files\n",
        "        # Extract the name of the original image from the piece name\n",
        "        image_name = filename.split(\"_\")[0]\n",
        "\n",
        "        # Load the image piece\n",
        "        piece_path = os.path.join(input_directory, filename)\n",
        "        piece = Image.open(piece_path)\n",
        "\n",
        "        # Add the piece to the list of pieces associated with the original image\n",
        "        if image_name not in image_pieces:\n",
        "            image_pieces[image_name] = []\n",
        "        image_pieces[image_name].append(piece)\n",
        "\n",
        "# Before reconstituting each image, sort the pieces by their intended order\n",
        "for image_name, pieces in image_pieces.items():\n",
        "    # Assuming your pieces are named with an ending number indicating their order\n",
        "    pieces_sorted = sorted(pieces, key=lambda x: int(x.filename.split('_')[-1].split('.')[0].replace('piece', '')))\n",
        "    # Output path for the reconstructed image\n",
        "    output_path = os.path.join(output_directory, f\"{image_name}_reconstructed.jpg\")\n",
        "    # Reconstruct the image with the sorted pieces and save\n",
        "    reconstruct_image(pieces_sorted, output_path)\n",
        "\n",
        "print(\"Reconstruction completed.\")\n"
      ],
      "metadata": {
        "id": "Me9GPv_guTtD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import shutil\n",
        "\n",
        "def empty_directory(directory):\n",
        "    \"\"\"\n",
        "    Vide un répertoire en supprimant tous ses fichiers et sous-répertoires.\n",
        "    Args:\n",
        "        directory (str): Chemin du répertoire à vider.\n",
        "    \"\"\"\n",
        "    for filename in os.listdir(directory):\n",
        "        file_path = os.path.join(directory, filename)\n",
        "        try:\n",
        "            if os.path.isfile(file_path) or os.path.islink(file_path):\n",
        "                os.unlink(file_path)\n",
        "            elif os.path.isdir(file_path):\n",
        "                shutil.rmtree(file_path)\n",
        "        except Exception as e:\n",
        "            print('Erreur lors de la suppression du fichier %s : %s' % (file_path, e))\n",
        "\n",
        "# Spécifiez les chemins des répertoires que vous souhaitez vider\n",
        "directories_to_empty = [\n",
        "    '/content/yolov5/runs/detect',\n",
        "    '/content/drive/MyDrive/ColabNotebooks/test/video',\n",
        "    '/content/drive/MyDrive/ColabNotebooks/test/imagesoutput',\n",
        "    '/content/drive/MyDrive/ColabNotebooks/test/imagesinput',\n",
        "    '/content/drive/MyDrive/ColabNotebooks/test/imagesdecoupees',\n",
        "\n",
        "    # Ajoutez d'autres répertoires au besoin\n",
        "]\n",
        "\n",
        "# Videz chaque répertoire spécifié\n",
        "for directory in directories_to_empty:\n",
        "    print(\"Vidage du répertoire :\", directory)\n",
        "    empty_directory(directory)\n"
      ],
      "metadata": {
        "id": "E7rxbWBnuaa5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.download(\"/content/yolov5/runs/train/exp/weights/best.pt\")"
      ],
      "metadata": {
        "id": "2Y2HvXBPubJ3"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}